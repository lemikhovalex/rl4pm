{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pm4py\n",
    "import pandas as pd\n",
    "import datetime\n",
    "from math import ceil\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import numpy as np\n",
    "import gym\n",
    "from importlib import reload\n",
    "import random\n",
    "from random import shuffle\n",
    "\n",
    "\n",
    "from IPython import display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data\n",
    "## Download and read\n",
    "- Download `.xes` file(archive) from [here](https://data.4tu.nl/articles/dataset/BPI_Challenge_2012/12689204)\n",
    "- Read this `.xes`\n",
    "- Convert to good old `.csv`\n",
    "\n",
    "## Drop data\n",
    "In the article only (activity, time_stamp) is used. Also leave trace id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    df = pd.read_csv('bpi_12.csv')\n",
    "    df['timestamp'] = df['timestamp'].apply(lambda x: datetime.datetime.fromisoformat(x))\n",
    "except FileNotFoundError:\n",
    "    file_path = 'BPI_Challenge_2012.xes'\n",
    "    event_log = pm4py.read_xes(file_path)\n",
    "    start_activities = pm4py.get_start_activities(event_log)\n",
    "    end_activities = pm4py.get_end_activities(event_log)\n",
    "    df = pm4py.convert_to_dataframe(event_log)\n",
    "    df = df[['time:timestamp', 'case:concept:name', 'concept:name']]\n",
    "    df = df.rename(columns={'time:timestamp': 'timestamp', 'case:concept:name': 'trace_id', 'concept:name': 'activity'})\n",
    "    df['trace_id'] = df['trace_id'].apply(lambda x: int(x))\n",
    "    df.to_csv('bpi_12.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time-related features\n",
    "\n",
    "- $t_{w}$ - time passed between Sunday midnight and the event\n",
    "- $t_e$ - time passed between the completion of the given event and the completion of the previous one\n",
    "- $t_t$ - time passed between the start of the trace and the given event\n",
    "\n",
    "### $t_w$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_t_w(df):\n",
    "    _df = df.copy()\n",
    "    _dt_s_mn = _df['timestamp'].apply(lambda x: (x - x.replace(hour=0, minute=0, second=0, microsecond=0)).total_seconds())\n",
    "    _dt_s_mn += _df['timestamp'].apply(lambda x: x.weekday() * 24 * 60 * 60)\n",
    "    return _dt_s_mn.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tw = get_t_w(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $t_e$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_t_e(df):\n",
    "    te = df['timestamp'].copy().diff()\n",
    "    tr_diff = df['trace_id'].diff().fillna(1)\n",
    "    te[tr_diff != 0] = 0.\n",
    "    return te.values * 1e-9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "te = get_t_e(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $t_t$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_t_t(df):\n",
    "    traces = list(set(df['trace_id']))\n",
    "    out = df.copy()[['timestamp', 'trace_id']]\n",
    "    t_ts = {}\n",
    "    for t in traces:\n",
    "        t_ts[t] = df['timestamp'][df['trace_id'] == t].min()\n",
    "    out['tt'] = out.apply(lambda x: (x['timestamp'] - t_ts[x['trace_id']]).total_seconds(), axis=1)\n",
    "    return out['tt'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt = get_t_t(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tt'] = tt\n",
    "df['te'] = te\n",
    "df['tw'] = tw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes = len(set(df['activity']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>trace_id</th>\n",
       "      <th>activity</th>\n",
       "      <th>tt</th>\n",
       "      <th>te</th>\n",
       "      <th>tw</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2011-10-01 00:38:44.546000+02:00</td>\n",
       "      <td>173688</td>\n",
       "      <td>A_SUBMITTED</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>434324.546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2011-10-01 00:38:44.880000+02:00</td>\n",
       "      <td>173688</td>\n",
       "      <td>A_PARTLYSUBMITTED</td>\n",
       "      <td>0.334</td>\n",
       "      <td>0.334</td>\n",
       "      <td>434324.880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2011-10-01 00:39:37.906000+02:00</td>\n",
       "      <td>173688</td>\n",
       "      <td>A_PREACCEPTED</td>\n",
       "      <td>53.360</td>\n",
       "      <td>53.026</td>\n",
       "      <td>434377.906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2011-10-01 00:39:38.875000+02:00</td>\n",
       "      <td>173688</td>\n",
       "      <td>W_Completeren aanvraag</td>\n",
       "      <td>54.329</td>\n",
       "      <td>0.969</td>\n",
       "      <td>434378.875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2011-10-01 11:36:46.437000+02:00</td>\n",
       "      <td>173688</td>\n",
       "      <td>W_Completeren aanvraag</td>\n",
       "      <td>39481.891</td>\n",
       "      <td>39427.562</td>\n",
       "      <td>473806.437</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          timestamp  trace_id                activity  \\\n",
       "0  2011-10-01 00:38:44.546000+02:00    173688             A_SUBMITTED   \n",
       "1  2011-10-01 00:38:44.880000+02:00    173688       A_PARTLYSUBMITTED   \n",
       "2  2011-10-01 00:39:37.906000+02:00    173688           A_PREACCEPTED   \n",
       "3  2011-10-01 00:39:38.875000+02:00    173688  W_Completeren aanvraag   \n",
       "4  2011-10-01 11:36:46.437000+02:00    173688  W_Completeren aanvraag   \n",
       "\n",
       "          tt         te          tw  \n",
       "0      0.000      0.000  434324.546  \n",
       "1      0.334      0.334  434324.880  \n",
       "2     53.360     53.026  434377.906  \n",
       "3     54.329      0.969  434378.875  \n",
       "4  39481.891  39427.562  473806.437  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling\n",
    "later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_tw(df):\n",
    "    df['tw'] = df['tw'] / (24 * 60 * 60)\n",
    "    return 24 * 60 * 60.\n",
    "    \n",
    "    \n",
    "def scale_tt(df):\n",
    "    traces = list(set(df['trace_id'].values))\n",
    "    max_tt = 0\n",
    "    for t_id in traces:\n",
    "        loc_df = df[df['trace_id'] == t_id]\n",
    "        max_time = loc_df['timestamp'].max()\n",
    "        min_time = loc_df['timestamp'].min()\n",
    "        _max_tt = (max_time - min_time).total_seconds()\n",
    "        if _max_tt > max_tt:\n",
    "            max_tt = _max_tt\n",
    "    df['tt'] = df['tt'] / max_tt\n",
    "    return max_tt\n",
    "\n",
    "\n",
    "def scale_te(df):\n",
    "    traces = list(set(df['trace_id'].values))\n",
    "    max_te = 0\n",
    "    for t_id in traces:\n",
    "        loc_df = df[df['trace_id'] == t_id]['te']\n",
    "        _max_te = loc_df.diff().dropna().max()\n",
    "        if _max_te > max_te:\n",
    "            max_te = _max_te\n",
    "    df['te'] = df['te'] / max_te\n",
    "    return max_te"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "86400.0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tw_scale = scale_tw(df)\n",
    "tw_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11855936.012"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tt_scale = scale_tt(df)\n",
    "tt_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8886255.847000001"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "te_scale = scale_te(df)\n",
    "te_scale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activity:\n",
    "one hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "traces = list(set(df['trace_id'].values))\n",
    "oh = pd.get_dummies(df['activity'])\n",
    "df = pd.concat([df, oh], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment\n",
    "Ther given scheme is the following:\n",
    "- recieving window of $(a_i,\\ t_{e,\\ i},\\ t_{w,\\ i},\\ t_{t,\\ i}) = e_i$. So the input to model is $\\{ e_{i},\\ e_{i-1},\\ \\dots,\\ e_{i-ws} \\}$ \n",
    "- prodice $\\hat{e}_{i+1}$\n",
    "- predict $\\hat{e}_{i+2}$ using $\\{ \\hat{e}_{i+1},\\ e_{i},\\ \\dots,\\ e_{i-ws +1} \\}$\n",
    "The metric is calculated by `environment`. It returns rewards for time prediction and for next step classifiation. So basicly `env` just stores data of trace. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Default predictor\n",
    "Need to develop(debug) `Env`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Predictor:\n",
    "    def __init__(self, default_te=60, default_act=8):\n",
    "        self.default_act = default_act\n",
    "        self.default_te = default_te\n",
    "    def predict_te(self, x):\n",
    "        in_sh = x.shape[0]\n",
    "        return torch.ones(in_sh) * self.default_te\n",
    "    \n",
    "    def predict_a(self, x):\n",
    "        in_sh = x.shape[0]\n",
    "        return torch.ones(in_sh) * self.default_act"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chose `[trace_id]` and create butch of traces, for learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'rl4pm_lib.utils' from 'C:\\\\Users\\\\PC\\\\Documents\\\\5th_course\\\\rl4pm\\\\rl4pm_lib\\\\utils.py'>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import rl4pm_lib.utils as utils\n",
    "reload(utils)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "env_trace_ids = traces[0: 8]\n",
    "\n",
    "env_matrix = utils.get_traces_matrix(df, env_trace_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These ara 'answers', and initial input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = 2\n",
    "predictor = Predictor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = env_matrix[:, :window_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([8., 8., 8., 8., 8., 8., 8., 8.])\n",
      "tensor([60., 60., 60., 60., 60., 60., 60., 60.])\n"
     ]
    }
   ],
   "source": [
    "a = predictor.predict_a(inp)\n",
    "te = predictor.predict_te(inp)\n",
    "print(a)\n",
    "print(te)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then this predictions are inputs for next event prediction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_feature = {'te': 0, 'tt': 1, 'tw': 2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'rl4pm_lib.envs' from 'C:\\\\Users\\\\PC\\\\Documents\\\\5th_course\\\\rl4pm\\\\rl4pm_lib\\\\envs.py'>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import rl4pm_lib.envs as envs\n",
    "reload(envs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "next_inp = envs.get_next_input(inp, a, te, column_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 3.9697, 63.9697], dtype=torch.float64)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_inp[0, :, 2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basicly this is for NN's predictions, but for env function which works with 1 event window is needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "next_inp_ = envs.get_next_input(inp[0].unsqueeze(0), a[0].unsqueeze(0), te[0].unsqueeze(0), column_feature)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 27])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_inp_.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Working is snippet is just above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also `env` returns a reward for predicion. Step is applied not for tensor of events for several traces, but for 1 event of trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "te_key_times = [0., 1., 10., 60., 120., 240., 480., 1440., 2880., 4320.,\n",
    "                7200., 10080., 14400., 20160., 30240., 40320., 50400.]\n",
    "te_intervals = [(te_key_times[i], te_key_times[i+1])\n",
    "             for i in range(len(te_key_times)-1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "true: 0.0038123838187077573\n",
      "pred: 60.0\n",
      "nice))))\n"
     ]
    }
   ],
   "source": [
    "# here wee neet counter to controll answers\n",
    "curr_step = 3\n",
    "trace = 2\n",
    "te_pred = next_inp[trace, -1, column_feature['tt']]\n",
    "te_true = env_matrix[trace, curr_step, column_feature['tt']]\n",
    "\n",
    "print(f'true: {te_true}\\npred: {te_pred}\\nnice))))')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 1])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true = torch.tensor([62., 700., 61.])\n",
    "pred = torch.tensor([700., 62., 62.]) \n",
    "envs.get_te_reward(true=true, pred=pred, intervals=te_intervals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "true = torch.tensor([62., 700., 61.])\n",
    "pred = torch.tensor([700., 62., 62.]) \n",
    "assert (envs.get_te_reward(true=true, pred=pred, intervals=te_intervals) == torch.tensor([0, 0, 1]).bool()).all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pipe line to deal with multiple traces needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert envs.get_act_reward(true_act_oh=torch.tensor([[1, 0, 0, 0]]), pred_act_oh=torch.tensor([[1, 0, 0, 0]])) == 1\n",
    "assert envs.get_act_reward(true_act_oh=torch.tensor([[0, 1, 0, 0]]), pred_act_oh=torch.tensor([[1, 0, 0, 0]])) == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 0])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "envs.get_act_reward(true_act_oh=torch.tensor([[1, 0, 0, 0],\n",
    "                                          [1, 0, 0, 0]\n",
    "                                         ]),\n",
    "                pred_act_oh=torch.tensor([[1, 0, 0, 0],\n",
    "                                          [0, 1, 0, 0]\n",
    "                                         ]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can prodice all the env must do in working cycle:\n",
    "```\n",
    "next_s, (reward_te, reward_act), is_done, add_inf = env.step(next_te, next_act)\n",
    "```\n",
    "Let's build class! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'rl4pm_lib.envs' from 'C:\\\\Users\\\\PC\\\\Documents\\\\5th_course\\\\rl4pm\\\\rl4pm_lib\\\\envs.py'>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from rl4pm_lib import envs\n",
    "reload(envs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gonna run this and go chill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(envs)\n",
    "env = envs.PMEnv(data=env_matrix, intervals_te_rew=te_intervals, column_to_time_features=column_feature, window_size=window_size)\n",
    "\n",
    "inp = env.reset()\n",
    "# predictor is a NN, it works with batches of states\n",
    "is_done = torch.zeros(env_matrix.shape[0]).bool()\n",
    "while not is_done.all():\n",
    "\n",
    "    n_traces = inp.shape[0]\n",
    "    next_act = predictor.predict_a(inp.view(n_traces, -1))\n",
    "    next_te = predictor.predict_te(inp.view(n_traces, -1))\n",
    "    inp, (reward_te, reward_act), is_done, add_inf = env.step(next_te, next_act)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM-based NN\n",
    "Ok here I gonna quiqly build some simply NN, which behaves just like predictor(which was used for debug).\n",
    "Later this NN will be used for Q-Learning\n",
    "``` python\n",
    "env_matrix = [n_traces=4, max_seq_len=52, features=27]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, output_layer, input_size=27 * 2, hidden_layer=64, n_lstm=1):\n",
    "        super(Net, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_size=input_size, hidden_size=hidden_layer, batch_first=True, num_layers=n_lstm)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc = nn.Linear(hidden_layer, output_layer)\n",
    "    \n",
    "    def forward(self, x, h):\n",
    "        x, (h, c) = self.lstm(x, (h[0], h[1]))\n",
    "        x = self.relu(x)\n",
    "        x = self.fc(x)\n",
    "        x = self.relu(x)\n",
    "        return x, (h, c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "input = (n_traces, max_len, features) # nn.LSTM(..., batch_first=True)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "output = out, (h, c)\n",
    "out.shape = (n_traces, max_len, features) # nn.LSTM(..., batch_first=True)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loop with env, LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(262200, 30)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(envs)\n",
    "env = envs.PMEnv(data=env_matrix, intervals_te_rew=te_intervals, column_to_time_features=column_feature, window_size=window_size)\n",
    "\n",
    "lstm_model_te = Net(output_layer=1).float()\n",
    "lstm_model_act = Net(output_layer=n_classes).float()\n",
    "\n",
    "inp = env.reset()\n",
    "n_traces = inp.shape[0]\n",
    "# predictor is a NN, it works with batches of states\n",
    "is_done = torch.zeros(env_matrix.shape[0]).bool()\n",
    "h_a = torch.zeros(1, n_traces, 64)\n",
    "c_a = torch.zeros(1, n_traces, 64)\n",
    "h_te = torch.zeros(1, n_traces, 64)\n",
    "c_te = torch.zeros(1, n_traces, 64)\n",
    "while not is_done.all():\n",
    "    inp = inp.view(n_traces, 1, -1).float()\n",
    "    next_act, (h_a, c_a) = lstm_model_act(inp, (h_a, c_a))\n",
    "    next_te, (h_te, c_te) = lstm_model_te(inp, (h_te, c_te))\n",
    "    \n",
    "    next_act = next_act.view(n_traces, -1)\n",
    "    next_act = next_act.argmax(dim=1).view(n_traces, -1)\n",
    "    \n",
    "    next_te = next_te.view(n_traces)\n",
    "        \n",
    "    inp, (reward_te, reward_act), is_done, add_inf = env.step(next_te, next_act)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agent\n",
    "### Nets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replay Buffer\n",
    "shamelessly stolen from [here](https://pytorch.org/tutorials/intermediate/reinforcement_q_learning.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'rl4pm_lib.replay_buffer' from 'C:\\\\Users\\\\PC\\\\Documents\\\\5th_course\\\\rl4pm\\\\rl4pm_lib\\\\replay_buffer.py'>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from rl4pm_lib import utils\n",
    "reload(utils)\n",
    "from rl4pm_lib import agents\n",
    "reload(agents)\n",
    "from rl4pm_lib import replay_buffer\n",
    "reload(replay_buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "replay_memory = replay_buffer.ReplayMemory(2 ** 12, traces=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = envs.PMEnv(data=env_matrix, intervals_te_rew=te_intervals, column_to_time_features=column_feature, window_size=window_size)\n",
    "\n",
    "hidden = 64\n",
    "\n",
    "te_agent = agents.AgentTeDiscrete(input_size=27 * 2, hidden_layer=hidden, n_lstm=4, te_intervals=te_intervals)\n",
    "ac_agent = agents.AgentAct(input_size=27 * 2, hidden_layer=hidden, n_lstm=4, out_shape=n_classes)\n",
    "\n",
    "lstm_model_act = Net(output_layer=n_classes).float()\n",
    "\n",
    "inp = env.reset()\n",
    "n_traces = inp.shape[0]\n",
    "inp = inp.view(n_traces, 1, -1).float()\n",
    "# predictor is a NN, it works with batches of states\n",
    "is_done = is_done = torch.zeros(env_matrix.shape[0]).bool()\n",
    "h_a = torch.zeros(4, n_traces, hidden)\n",
    "c_a = torch.zeros(4, n_traces, hidden)\n",
    "h_t = torch.zeros(4, n_traces, hidden)\n",
    "c_t = torch.zeros(4, n_traces, hidden)\n",
    "while not is_done.all():\n",
    "    state_t = replay_buffer.State(state=inp, h_ac=h_a, c_ac=c_a,\n",
    "                        h_te=h_t, c_te=c_t)\n",
    "    next_ac, (h_a, c_a) = ac_agent.sample_action(x=inp, hidden=(h_a, c_a))\n",
    "    next_te, (h_t, c_t) = te_agent.sample_action(x=inp, hidden=(h_t, c_t))\n",
    "    \n",
    "    n_inp, (reward_te, reward_ac), is_done, add_inf = env.step(te_agent.act_to_te(next_te), next_ac)\n",
    "    n_inp = n_inp.view(n_traces, 1, -1).float()\n",
    "    state_t_next = replay_buffer.State(state=n_inp, h_ac=h_a, c_ac=c_a,\n",
    "                             h_te=h_t, c_te=c_t)\n",
    "\n",
    "    datum = replay_buffer.Datum(obs_t=state_t, action_te=next_te, action_ac=next_ac, reward_ac=reward_ac, reward_te=reward_te,\n",
    "                      obs_tp1=state_t_next, dones=is_done)\n",
    "    replay_memory.push(datum)\n",
    "    \n",
    "    inp = n_inp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agncy\n",
    "Here agent got trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 82, 27])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replay_memory.sample(1)[0]['s'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from rl4pm_lib import agencies\n",
    "reload(agencies)\n",
    "_ = env.reset()\n",
    "batch_size = 128\n",
    "\n",
    "agency = agencies.Agency(input_size=27 * 2, hidden=hidden, n_lstm=7, te_intervals=te_intervals, ac_learning_rate=1e-3,\n",
    "                 te_learning_rate=1e-3, n_classes=n_classes, discount_factor=0.9)\n",
    "replay_memory = replay_buffer.ReplayMemory(2 ** 12, traces=8)\n",
    "with torch.no_grad():\n",
    "    episode_te_rew, episode_ac_rew, n = utils.play_and_record(agency.te_agent, agency.ac_agent, env, replay_memory)\n",
    "ep_te_loss, ep_ac_loss = agency.train(replay_memory, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0]],\n",
       "\n",
       "        [[ 5]],\n",
       "\n",
       "        [[10]],\n",
       "\n",
       "        [[14]],\n",
       "\n",
       "        [[17]],\n",
       "\n",
       "        [[20]]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = torch.tensor(list(range(2 * 3 * 4))).view(6, 1, 4)\n",
    "indexes = torch.tensor([[0], [1], [2], [2], [1], [0]])\n",
    "torch.gather(input=t , index=indexes.unsqueeze(2), dim=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6, 1])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indexes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6, 1, 4])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import floor, ceil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_list_to_buckets(array, n):\n",
    "    n_buckets = ceil(len(array) / n)\n",
    "    n_full_buckets = floor(len(array) / n)\n",
    "    extra_size = n_buckets * n - len(array)\n",
    "    out = []\n",
    "    fp = 0\n",
    "    lp = n\n",
    "    for i in range(n_buckets):\n",
    "        lp = lp - int(extra_size > 0)\n",
    "        out.append(array[fp: lp])\n",
    "        extra_size -= 1\n",
    "        fp = lp\n",
    "        lp += n\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "traces = list(set(df['trace_id'].values))\n",
    "traces_len = {}\n",
    "for t in traces:\n",
    "    trace_len = df[df['trace_id'] == t].shape[0]\n",
    "    if trace_len > window_size:\n",
    "        traces_len[t] = df[df['trace_id'] == t].shape[0]\n",
    "\n",
    "    \n",
    "traces_len_sorted = dict(sorted(traces_len.items(), key=lambda item: item[1]))\n",
    "traces = list(traces_len_sorted.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_to_fixed_bucket(array, bucket_size, fill_none=True):\n",
    "    index = len(array)\n",
    "    out = []\n",
    "    while index > 0:\n",
    "        beg = max(0, index - bucket_size)\n",
    "        end = index\n",
    "        out.append(array[beg: end])\n",
    "        index -= bucket_size\n",
    "    out[-1].extend([None] * (-1 * index))\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[6, 7, 8], [3, 4, 5], [1, 2, None]]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_to_fixed_bucket([1, 2, 3, 4, 5, 6, 7, 8], 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(envs)\n",
    "reload(utils)\n",
    "traces = list(set(df['trace_id'].values))\n",
    "shuffle(traces)\n",
    "# traces = traces[:2048]\n",
    "n_traces = 256\n",
    "\n",
    "ix_4_envs = split_to_fixed_bucket(traces, n_traces)\n",
    "n_envs = len(ix_4_envs)\n",
    "envirs = []\n",
    "for _i in range(n_envs):\n",
    "    env_matrix = utils.get_traces_matrix(df, ix_4_envs[_i])\n",
    "    envirs.append(envs.PMEnv(data=env_matrix, intervals_te_rew=te_intervals,\n",
    "                 column_to_time_features=column_feature, window_size=window_size)\n",
    "               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(agents)\n",
    "reload(agencies)\n",
    "reload(utils)\n",
    "batch_size = 2 ** 17\n",
    "replay_memory = replay_buffer.ReplayMemory(2 ** 20 // n_traces, n_traces)\n",
    "agency = agencies.Agency(input_size=27 * 2, hidden=hidden, n_lstm=1, te_intervals=te_intervals, ac_learning_rate=1e-3,\n",
    "                         te_learning_rate=1e-3, n_classes=n_classes, discount_factor=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/52\r"
     ]
    }
   ],
   "source": [
    "te_rewards = []\n",
    "ac_rewards = []\n",
    "for epoch in range(30):\n",
    "    te_rw, ac_rw, n = 0, 0, 0\n",
    "    for _i in range(n_envs):\n",
    "        print(f'{_i+1}/{n_envs}', end='\\r')\n",
    "        _ = envirs[_i].reset()\n",
    "        with torch.no_grad():\n",
    "                _episode_te_rew, _episode_ac_rew, n_ep = utils.play_and_record(agency.te_agent, agency.ac_agent,\n",
    "                                                                               envirs[_i], replay_memory)\n",
    "                te_rw += _episode_te_rew\n",
    "                ac_rw += _episode_ac_rew\n",
    "                n += n_ep\n",
    "        if len(replay_memory) == replay_memory._maxsize:\n",
    "            ep_te_loss, ep_ac_loss = agency.train(replay_memory, batch_size)\n",
    "        # print(ep_te_rew, ep_te_rew, n_samples)\n",
    "        \n",
    "    ep_te_loss, ep_ac_loss = agency.train(replay_memory, batch_size)\n",
    "    n = batch_size * n_envs\n",
    "    te_rewards.append(te_rw / n)\n",
    "    ac_rewards.append(ac_rw / n)\n",
    "    \n",
    "    display.clear_output(wait=True)\n",
    "    plt.plot(te_rewards, label='$t_e$')\n",
    "    plt.plot(ac_rewards, label='next activity')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('accaracy')\n",
    "    plt.title('Accuracy score for \\n $t_e$ and next activity prediction')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1193984 / 64 / 4664"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "replay_memory.traces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "int(len(replay_memory) * 0.8 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(agencies)\n",
    "agency = agencies.Agency(input_size=27 * 2, hidden=hidden, n_lstm=1, te_intervals=te_intervals, ac_learning_rate=1e-3,\n",
    "                         te_learning_rate=1e-3, n_classes=n_classes, discount_factor=0.9)\n",
    "ep_te_loss, ep_ac_loss = agency.train(replay_memory, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "replay_memory._storage[0].obs_t.state.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(ac_rewards)\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('accaracy')\n",
    "plt.title('Accuracy score for \\n $t_e$ prediction')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "states, actions_te, actions_ac, rewards_te, rewards_ac, next_states, is_dones = replay_memory.sample(256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "states, actions_te, actions_ac, rewards_te, rewards_ac, next_states, is_dones = buffers[0].sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = envirs[0].reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(envs)\n",
    "reload(utils)\n",
    "\n",
    "env_matrix = utils.get_traces_matrix(df, ix_4_envs[6])\n",
    "env = envs.PMEnv(data=env_matrix, intervals_te_rew=te_intervals,\n",
    "                 column_to_time_features=column_feature, window_size=window_size)\n",
    "               \n",
    "buffer = utils.ReplayMemory(2 ** 12)\n",
    "\n",
    "episode_te_rew, episode_ac_rew, n = utils.play_and_record(agency.te_agent, agency.ac_agent,  env, buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "episode_te_rew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "episode_ac_rew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_traces = s.shape[0]\n",
    "s = s.view(n_traces, 1, -1).float()\n",
    "h_a = torch.zeros(1, n_traces, agency.te_agent.hidden)\n",
    "c_a = torch.zeros(1, n_traces, agency.te_agent.hidden)\n",
    "te_n = agency.te_agent.sample_action(s, (h_a, c_a))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = torch.tensor([0, 0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(6):\n",
    "    x += t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "te_te_pred = agency.te_agent.act_to_te(te_n)\n",
    "te_te_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "te_n, te_n.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agency.te_agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_tes = envirs[0].data[:, window_size+1, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answers = []\n",
    "for _i, te in enumerate(true_tes):\n",
    "    app = False\n",
    "    for te_num, te_int in enumerate(te_intervals):\n",
    "        if (te >= te_int[0]) & (te < te_int[1]):\n",
    "            answers.append(te_num)\n",
    "            app = True\n",
    "    if not app:\n",
    "        answers.append(-1)\n",
    "answers = torch.tensor(answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answers, answers.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(answers == te_n).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_te_reward(true: torch.tensor, pred: torch.tensor, te_intervals):\n",
    "    masks = []\n",
    "    for inter in intervals:\n",
    "        true_here = (true >= inter[0]) * (true < inter[1])\n",
    "        pred_here = (pred >= inter[0]) * (pred < inter[1])\n",
    "        masks.append(true_here * pred_here)\n",
    "    out = torch.stack(masks).T.sum(dim=1)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_te_reward(true=true_tes, pred=te_te_pred, intervals=te_intervals).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ep_te_rew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ep_te_rew"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
