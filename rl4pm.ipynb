{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pm4py\n",
    "import pandas as pd\n",
    "import datetime\n",
    "from math import ceil\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import numpy as np\n",
    "import gym"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data\n",
    "## Download and read\n",
    "- Download `.xes` file(archive) from [here](https://data.4tu.nl/articles/dataset/BPI_Challenge_2012/12689204)\n",
    "- Read this `.xes`\n",
    "- Convert to good old `.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d866601dae44f04ad317c19f80e40fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='parsing log, completed traces :: '), FloatProgress(value=0.0, max=13087.0), HTML(va…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "file_path = 'BPI_Challenge_2012.xes'\n",
    "event_log = pm4py.read_xes(file_path)\n",
    "start_activities = pm4py.get_start_activities(event_log)\n",
    "end_activities = pm4py.get_end_activities(event_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pm4py.convert_to_dataframe(event_log)\n",
    "df.to_csv('bpi_12.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drop data\n",
    "In the article only (activity, time_stamp) is used. Also leave trace id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['time:timestamp', 'case:concept:name', 'concept:name']]\n",
    "df = df.rename(columns={'time:timestamp': 'timestamp', 'case:concept:name': 'trace_id', 'concept:name': 'activity'})\n",
    "df['trace_id'] = df['trace_id'].apply(lambda x: int(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time-related features\n",
    "\n",
    "- $t_{w}$ - time passed between Sunday midnight and the event\n",
    "- $t_e$ - time passed between the completion of the given event and the completion of the previous one\n",
    "- $t_t$ - time passed between the start of the trace and the given event\n",
    "\n",
    "### $t_w$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_t_w(df):\n",
    "    _df = df.copy()\n",
    "    _dt_s_mn = _df['timestamp'].apply(lambda x: (x - x.replace(hour=0, minute=0, second=0, microsecond=0)).total_seconds())\n",
    "    _dt_s_mn += _df['timestamp'].apply(lambda x: x.weekday() * 24 * 60 * 60)\n",
    "    return _dt_s_mn.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tw = get_t_w(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $t_e$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_t_e(df):\n",
    "    te = df['timestamp'].copy().diff()\n",
    "    tr_diff = df['trace_id'].diff().fillna(1)\n",
    "    te[tr_diff != 0] = 0\n",
    "    return te.values * 1e-9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "te = get_t_e(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $t_t$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_t_t(df):\n",
    "    traces = list(set(df['trace_id']))\n",
    "    out = df.copy()[['timestamp', 'trace_id']]\n",
    "    t_ts = {}\n",
    "    for t in traces:\n",
    "        t_ts[t] = df['timestamp'][df['trace_id'] == t].min()\n",
    "    out['tt'] = out.apply(lambda x: (x['timestamp'] - t_ts[x['trace_id']]).total_seconds(), axis=1)\n",
    "    return out['tt'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt = get_t_t(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tt'] = tt\n",
    "df['te'] = te\n",
    "df['tw'] = tw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>trace_id</th>\n",
       "      <th>activity</th>\n",
       "      <th>tt</th>\n",
       "      <th>te</th>\n",
       "      <th>tw</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2011-10-01 00:38:44.546000+02:00</td>\n",
       "      <td>173688</td>\n",
       "      <td>A_SUBMITTED</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>434324.546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2011-10-01 00:38:44.880000+02:00</td>\n",
       "      <td>173688</td>\n",
       "      <td>A_PARTLYSUBMITTED</td>\n",
       "      <td>0.334</td>\n",
       "      <td>0.334</td>\n",
       "      <td>434324.880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2011-10-01 00:39:37.906000+02:00</td>\n",
       "      <td>173688</td>\n",
       "      <td>A_PREACCEPTED</td>\n",
       "      <td>53.360</td>\n",
       "      <td>53.026</td>\n",
       "      <td>434377.906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2011-10-01 00:39:38.875000+02:00</td>\n",
       "      <td>173688</td>\n",
       "      <td>W_Completeren aanvraag</td>\n",
       "      <td>54.329</td>\n",
       "      <td>0.969</td>\n",
       "      <td>434378.875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2011-10-01 11:36:46.437000+02:00</td>\n",
       "      <td>173688</td>\n",
       "      <td>W_Completeren aanvraag</td>\n",
       "      <td>39481.891</td>\n",
       "      <td>39427.562</td>\n",
       "      <td>473806.437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262195</th>\n",
       "      <td>2012-02-29 23:51:17.423000+01:00</td>\n",
       "      <td>214376</td>\n",
       "      <td>A_PARTLYSUBMITTED</td>\n",
       "      <td>0.624</td>\n",
       "      <td>0.624</td>\n",
       "      <td>258677.423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262196</th>\n",
       "      <td>2012-02-29 23:52:01.287000+01:00</td>\n",
       "      <td>214376</td>\n",
       "      <td>W_Afhandelen leads</td>\n",
       "      <td>44.488</td>\n",
       "      <td>43.864</td>\n",
       "      <td>258721.287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262197</th>\n",
       "      <td>2012-03-01 09:26:46.736000+01:00</td>\n",
       "      <td>214376</td>\n",
       "      <td>W_Afhandelen leads</td>\n",
       "      <td>34529.937</td>\n",
       "      <td>34485.449</td>\n",
       "      <td>293206.736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262198</th>\n",
       "      <td>2012-03-01 09:27:37.118000+01:00</td>\n",
       "      <td>214376</td>\n",
       "      <td>A_DECLINED</td>\n",
       "      <td>34580.319</td>\n",
       "      <td>50.382</td>\n",
       "      <td>293257.118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262199</th>\n",
       "      <td>2012-03-01 09:27:41.325000+01:00</td>\n",
       "      <td>214376</td>\n",
       "      <td>W_Afhandelen leads</td>\n",
       "      <td>34584.526</td>\n",
       "      <td>4.207</td>\n",
       "      <td>293261.325</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>262200 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               timestamp  trace_id                activity  \\\n",
       "0       2011-10-01 00:38:44.546000+02:00    173688             A_SUBMITTED   \n",
       "1       2011-10-01 00:38:44.880000+02:00    173688       A_PARTLYSUBMITTED   \n",
       "2       2011-10-01 00:39:37.906000+02:00    173688           A_PREACCEPTED   \n",
       "3       2011-10-01 00:39:38.875000+02:00    173688  W_Completeren aanvraag   \n",
       "4       2011-10-01 11:36:46.437000+02:00    173688  W_Completeren aanvraag   \n",
       "...                                  ...       ...                     ...   \n",
       "262195  2012-02-29 23:51:17.423000+01:00    214376       A_PARTLYSUBMITTED   \n",
       "262196  2012-02-29 23:52:01.287000+01:00    214376      W_Afhandelen leads   \n",
       "262197  2012-03-01 09:26:46.736000+01:00    214376      W_Afhandelen leads   \n",
       "262198  2012-03-01 09:27:37.118000+01:00    214376              A_DECLINED   \n",
       "262199  2012-03-01 09:27:41.325000+01:00    214376      W_Afhandelen leads   \n",
       "\n",
       "               tt         te          tw  \n",
       "0           0.000      0.000  434324.546  \n",
       "1           0.334      0.334  434324.880  \n",
       "2          53.360     53.026  434377.906  \n",
       "3          54.329      0.969  434378.875  \n",
       "4       39481.891  39427.562  473806.437  \n",
       "...           ...        ...         ...  \n",
       "262195      0.624      0.624  258677.423  \n",
       "262196     44.488     43.864  258721.287  \n",
       "262197  34529.937  34485.449  293206.736  \n",
       "262198  34580.319     50.382  293257.118  \n",
       "262199  34584.526      4.207  293261.325  \n",
       "\n",
       "[262200 rows x 6 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling\n",
    "later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activity:\n",
    "one hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "oh = pd.get_dummies(df['activity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df, oh], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment\n",
    "Ther given scheme is the following:\n",
    "- recieving window of $(a_i,\\ t_{e,\\ i},\\ t_{w,\\ i},\\ t_{t,\\ i}) = e_i$. So the input to model is $\\{ e_{i},\\ e_{i-1},\\ \\dots,\\ e_{i-ws} \\}$ \n",
    "- prodice $\\hat{e}_{i+1}$\n",
    "- predict $\\hat{e}_{i+2}$ using $\\{ \\hat{e}_{i+1},\\ e_{i},\\ \\dots,\\ e_{i-ws +1} \\}$\n",
    "The metric is calculated by `environment`. It returns rewards for time prediction and for next step classifiation. So basicly `env` just stores data of trace. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Default predictor\n",
    "Need to develop(debug) `Env`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Predictor:\n",
    "    def __init__(self, default_te=60, default_act=8):\n",
    "        self.default_act = default_act\n",
    "        self.default_te = default_te\n",
    "    def predict_te(self, x):\n",
    "        in_sh = x.shape[0]\n",
    "        return torch.ones(in_sh) * self.default_te\n",
    "    \n",
    "    def predict_a(self, x):\n",
    "        in_sh = x.shape[0]\n",
    "        return torch.ones(in_sh) * self.default_act"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chose `[trace_id]` and create butch of traces, for learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_trace(trace_np_matrix, max_len):\n",
    "    need_pad = max_len - trace_np_matrix.shape[0]\n",
    "    pad = np.zeros((need_pad, trace_np_matrix.shape[1]))\n",
    "    return np.concatenate((trace_np_matrix, pad))\n",
    "\n",
    "def extract_trace_features(df, trace_id, max_len):\n",
    "    df_id = df[df['trace_id'] == t_id].drop(columns=['timestamp', 'trace_id', 'activity'])\n",
    "    trace_vals = df_id.values\n",
    "    trace_vals = fill_trace(trace_vals, max_len)\n",
    "    trace_vals = torch.as_tensor(trace_vals).unsqueeze(0)\n",
    "    return trace_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_trace_ids = list(set(df['trace_id'].values))[0: 4]\n",
    "env_matrix = None\n",
    "max_len = 0\n",
    "for t_id in env_trace_ids:\n",
    "    trace_len = df[df['trace_id'] == t_id].shape[0]\n",
    "    if max_len < trace_len:\n",
    "        max_len = trace_len\n",
    "        \n",
    "\n",
    "for _i, t_id in enumerate(env_trace_ids):\n",
    "    if env_matrix is not None:\n",
    "        \n",
    "        trace_vals = extract_trace_features(df, t_id, max_len)\n",
    "        env_matrix = torch.cat([env_matrix, trace_vals])\n",
    "    else:\n",
    "        env_matrix = extract_trace_features(df, t_id, max_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These ara 'answers', and initial input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = 2\n",
    "predictor = Predictor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = env_matrix[:, :window_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([8., 8., 8., 8.])\n",
      "tensor([60., 60., 60., 60.])\n"
     ]
    }
   ],
   "source": [
    "a = predictor.predict_a(inp)\n",
    "te = predictor.predict_te(inp)\n",
    "print(a)\n",
    "print(te)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then this predictions are inputs for next event prediction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_feature = {'te': 0, 'tt': 1, 'tw': 2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_next_input(prev_inp, next_act, next_te, column_feature):\n",
    "    out = prev_inp[:, 1:]\n",
    "    next_event = torch.zeros(prev_inp.shape[0], prev_inp.shape[2])\n",
    "    next_event[:, column_feature['te']] = next_te\n",
    "    last_event = prev_inp[:, -1].squeeze(1)\n",
    "    \n",
    "    next_event[:, column_feature['tt']] = last_event[:, column_feature['tt']] + next_te\n",
    "    \n",
    "    next_event[:, column_feature['tw']] = (last_event[:, column_feature['tw']] + next_te ) % (7 * 24 * 60 * 60)\n",
    "    # one hot transformation from https://discuss.pytorch.org/t/convert-int-into-one-hot-format/507/5\n",
    "    act_onehot = torch.FloatTensor(out.shape[0], out.shape[2] - len(column_feature))\n",
    "    act_onehot.zero_()\n",
    "    act_onehot.scatter_(1, next_act.long().view(-1, 1), 1)\n",
    "    next_event[:, len(column_feature):] = act_onehot\n",
    "\n",
    "    out = torch.cat([out, next_event.unsqueeze(1)], dim=1)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "next_inp = get_next_input(inp, a, te, column_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([342983.8270, 343043.8125], dtype=torch.float64)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_inp[0, :, 2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basicly this is for NN's predictions, but for env function which works with 1 event window is needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "next_inp_ = get_next_input(inp[0].unsqueeze(0), a[0].unsqueeze(0), te[0].unsqueeze(0), column_feature)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 27])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_inp_.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Working is snippet is just above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also `env` returns a reward for predicion. Step is applied not for tensor of events for several traces, but for 1 event of trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "te_key_times = [0., 1., 10., 60., 120., 240., 480., 1440., 2880., 4320.,\n",
    "                7200., 10080., 14400., 20160., 30240., 40320., 50400.]\n",
    "te_intervals = [(te_key_times[i], te_key_times[i+1])\n",
    "             for i in range(len(te_key_times)-1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "true: 33877.818\n",
      "pred: 60.14899826049805\n",
      "nice))))\n"
     ]
    }
   ],
   "source": [
    "# here wee neet counter to controll answers\n",
    "curr_step = 3\n",
    "trace = 2\n",
    "te_pred = next_inp[trace, -1, column_feature['tt']]\n",
    "te_true = env_matrix[trace, curr_step, column_feature['tt']]\n",
    "\n",
    "print(f'true: {te_true}\\npred: {te_pred}\\nnice))))')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_te_reward(true: torch.tensor, pred: torch.tensor, intervals):\n",
    "    for inter in intervals:\n",
    "        if (true >= inter[0]) & (true < inter[1]): # got true value in this interval\n",
    "            if (pred >= inter[0]) & (pred < inter[1]):\n",
    "                return 1\n",
    "            else:\n",
    "                return 0\n",
    "        if (pred >= inter[0]) & (pred < inter[1]): # got pred value in this interval\n",
    "            return 0\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_te_reward(true: torch.tensor, pred: torch.tensor, intervals):\n",
    "    masks = []\n",
    "    for inter in intervals:\n",
    "        true_here = (true >= inter[0]) * (true < inter[1]) \n",
    "        pred_here = (pred >= inter[0]) * (pred < inter[1])\n",
    "        masks.append(true_here * pred_here)\n",
    "    out = torch.stack(masks).T.sum(dim=1)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 1])"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true = torch.tensor([62., 700., 61.])\n",
    "pred = torch.tensor([700., 62., 62.]) \n",
    "get_te_reward(true=true, pred=pred, intervals=te_intervals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "true = torch.tensor([62., 700., 61.])\n",
    "pred = torch.tensor([700., 62., 62.]) \n",
    "assert (get_te_reward(true=true, pred=pred, intervals=te_intervals) == torch.tensor([0, 0, 1]).bool()).all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pipe line to deal with multiple traces needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_act_reward(true_act_oh, pred_act_oh):\n",
    "    mult = (true_act_oh * pred_act_oh)\n",
    "    return mult.sum(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert get_act_reward(true_act_oh=torch.tensor([[1, 0, 0, 0]]), pred_act_oh=torch.tensor([[1, 0, 0, 0]])) == 1\n",
    "assert get_act_reward(true_act_oh=torch.tensor([[0, 1, 0, 0]]), pred_act_oh=torch.tensor([[1, 0, 0, 0]])) == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 0])"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " get_act_reward(true_act_oh=torch.tensor([[1, 0, 0, 0],\n",
    "                                          [1, 0, 0, 0]\n",
    "                                         ]),\n",
    "                pred_act_oh=torch.tensor([[1, 0, 0, 0],\n",
    "                                          [0, 1, 0, 0]\n",
    "                                         ]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can prodice all the env must do in working cycle:\n",
    "```\n",
    "next_s, (reward_te, reward_act), is_done, add_inf = env.step(next_te, next_act)\n",
    "```\n",
    "Let's build class! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PMEnv(gym.Env):\n",
    "    def __init__(self, data: torch.tensor, intervals_te_rew, column_to_time_features, window_size):\n",
    "        self.data = data\n",
    "        self.pred_counter = 1 + window_size\n",
    "        self.trace_index = None\n",
    "        self.intervals = intervals_te_rew\n",
    "        self.column_feature = column_to_time_features\n",
    "        self.win = window_size\n",
    "        self.given_state = None\n",
    "        \n",
    "    def reset(self, trace_n=None):\n",
    "        self.pred_counter = 1 + self.win\n",
    "        out = self.data[:, :window_size]\n",
    "        self.given_state = out\n",
    "        self.trace_index = trace_n\n",
    "        return out\n",
    "        \n",
    "    def step(self, next_te: torch.tensor, next_act: torch.tensor):\n",
    "        '''\n",
    "        returns: next_s, (reward_te, reward_act), is_done, add_inf\n",
    "        '''\n",
    "        te_rew = get_te_reward(true=self.data[:, self.pred_counter, self.column_feature['te']],\n",
    "                               pred=next_te, intervals=self.intervals)\n",
    "        \n",
    "        true_act_oh = self.data[:, self.pred_counter, len(column_feature):]\n",
    "\n",
    "        # TODO here rises an error\n",
    "        pred_act_oh = torch.zeros(self.data.shape[0], self.data.shape[-1] - len(self.column_feature), dtype=int)\n",
    "        pred_act_oh[range(pred_act_oh.shape[0]), next_act.long()] = 1\n",
    "        \n",
    "        act_rew = get_act_reward(true_act_oh=true_act_oh, pred_act_oh=pred_act_oh)\n",
    "        \n",
    "        next_s = get_next_input(prev_inp=self.given_state,\n",
    "                                next_act=next_act,\n",
    "                                next_te=next_te,\n",
    "                                column_feature=self.column_feature)\n",
    "        self.given_state = next_s\n",
    "        \n",
    "        is_done = (self.pred_counter == (self.data.shape[1] - 1))\n",
    "        \n",
    "        self.pred_counter += 1\n",
    "        return next_s, (te_rew, act_rew), is_done, {}\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gonna run this and go chill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 52, 27])\n"
     ]
    }
   ],
   "source": [
    "print(env_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = PMEnv(data=env_matrix, intervals_te_rew=te_intervals, column_to_time_features=column_feature, window_size=window_size)\n",
    "\n",
    "inp = env.reset()\n",
    "# predictor is a NN, it works with batches of states\n",
    "is_done = False\n",
    "while not is_done:\n",
    "    n_traces = inp.shape[0]\n",
    "    next_act = predictor.predict_a(inp.view(n_traces, -1))\n",
    "    next_te = predictor.predict_te(inp.view(n_traces, -1))\n",
    "    inp, (reward_te, reward_act), is_done, add_inf = env.step(next_te, next_act)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM-based NN\n",
    "Ok here I gonna quiqly build some simply NN, which behaves just like predictor(which was used for debug).\n",
    "Later this NN will be used for Q-Learning\n",
    "``` python\n",
    "env_matrix = [n_traces=4, max_seq_len=52, features=27]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, output_layer, input_size=27, hidden_layer=64, n_lstm=1):\n",
    "        super(Net, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_size=input_size, hidden_size=hidden_layer, batch_first=True, num_layers=n_lstm)\n",
    "        self.fc = nn.Linear(hidden_layer, output_layer)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x, (h, c) = self.lstm(x)\n",
    "        return self.fc(x), (h, c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "input = (n_traces, max_len, features) # nn.LSTM(..., batch_first=True)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_model = Net(output_layer=1).float()\n",
    "_rnn_inp = env_matrix.float()\n",
    "out, (_, _) = lstm_model(_rnn_inp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "output = out, (h, c)\n",
    "out.shape = (n_traces, max_len, features) # nn.LSTM(..., batch_first=True)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training loop with env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = PMEnv(data=env_matrix, intervals_te_rew=te_intervals, column_to_time_features=column_feature, window_size=window_size)\n",
    "\n",
    "inp = env.reset(0)\n",
    "# predictor is a NN, it works with batches of states\n",
    "is_done = False\n",
    "while not is_done:\n",
    "    next_act = int(predictor.predict_a(inp)[0].item())\n",
    "    next_te = predictor.predict_te(inp)[0].item()\n",
    "\n",
    "    next_s, (reward_te, reward_act), is_done, add_inf = env.step(next_te, next_act)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
