{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pm4py\n",
    "import pandas as pd\n",
    "import datetime\n",
    "from math import ceil\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import numpy as np\n",
    "import gym"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data\n",
    "## Download and read\n",
    "- Download `.xes` file(archive) from [here](https://data.4tu.nl/articles/dataset/BPI_Challenge_2012/12689204)\n",
    "- Read this `.xes`\n",
    "- Convert to good old `.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d39b791f9fd44009fc8f1b0987b05f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='parsing log, completed traces :: '), FloatProgress(value=0.0, max=13087.0), HTML(va…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "file_path = 'BPI_Challenge_2012.xes'\n",
    "event_log = pm4py.read_xes(file_path)\n",
    "start_activities = pm4py.get_start_activities(event_log)\n",
    "end_activities = pm4py.get_end_activities(event_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pm4py.convert_to_dataframe(event_log)\n",
    "df.to_csv('bpi_12.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drop data\n",
    "In the article only (activity, time_stamp) is used. Also leave trace id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['time:timestamp', 'case:concept:name', 'concept:name']]\n",
    "df = df.rename(columns={'time:timestamp': 'timestamp', 'case:concept:name': 'trace_id', 'concept:name': 'activity'})\n",
    "df['trace_id'] = df['trace_id'].apply(lambda x: int(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time-related features\n",
    "\n",
    "- $t_{w}$ - time passed between Sunday midnight and the event\n",
    "- $t_e$ - time passed between the completion of the given event and the completion of the previous one\n",
    "- $t_t$ - time passed between the start of the trace and the given event\n",
    "\n",
    "### $t_w$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_t_w(df):\n",
    "    _df = df.copy()\n",
    "    _dt_s_mn = _df['timestamp'].apply(lambda x: (x - x.replace(hour=0, minute=0, second=0, microsecond=0)).total_seconds())\n",
    "    _dt_s_mn += _df['timestamp'].apply(lambda x: x.weekday() * 24 * 60 * 60)\n",
    "    return _dt_s_mn.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tw = get_t_w(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $t_e$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_t_e(df):\n",
    "    te = df['timestamp'].copy().diff()\n",
    "    tr_diff = df['trace_id'].diff().fillna(1)\n",
    "    te[tr_diff != 0] = 0\n",
    "    return te.values * 1e-9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "te = get_t_e(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $t_t$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_t_t(df):\n",
    "    traces = list(set(df['trace_id']))\n",
    "    out = df.copy()[['timestamp', 'trace_id']]\n",
    "    t_ts = {}\n",
    "    for t in traces:\n",
    "        t_ts[t] = df['timestamp'][df['trace_id'] == t].min()\n",
    "    out['tt'] = out.apply(lambda x: (x['timestamp'] - t_ts[x['trace_id']]).total_seconds(), axis=1)\n",
    "    return out['tt'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt = get_t_t(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tt'] = tt\n",
    "df['te'] = te\n",
    "df['tw'] = tw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes = len(set(df['activity']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>trace_id</th>\n",
       "      <th>activity</th>\n",
       "      <th>tt</th>\n",
       "      <th>te</th>\n",
       "      <th>tw</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2011-10-01 00:38:44.546000+02:00</td>\n",
       "      <td>173688</td>\n",
       "      <td>A_SUBMITTED</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>434324.546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2011-10-01 00:38:44.880000+02:00</td>\n",
       "      <td>173688</td>\n",
       "      <td>A_PARTLYSUBMITTED</td>\n",
       "      <td>0.334</td>\n",
       "      <td>0.334</td>\n",
       "      <td>434324.880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2011-10-01 00:39:37.906000+02:00</td>\n",
       "      <td>173688</td>\n",
       "      <td>A_PREACCEPTED</td>\n",
       "      <td>53.360</td>\n",
       "      <td>53.026</td>\n",
       "      <td>434377.906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2011-10-01 00:39:38.875000+02:00</td>\n",
       "      <td>173688</td>\n",
       "      <td>W_Completeren aanvraag</td>\n",
       "      <td>54.329</td>\n",
       "      <td>0.969</td>\n",
       "      <td>434378.875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2011-10-01 11:36:46.437000+02:00</td>\n",
       "      <td>173688</td>\n",
       "      <td>W_Completeren aanvraag</td>\n",
       "      <td>39481.891</td>\n",
       "      <td>39427.562</td>\n",
       "      <td>473806.437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262195</th>\n",
       "      <td>2012-02-29 23:51:17.423000+01:00</td>\n",
       "      <td>214376</td>\n",
       "      <td>A_PARTLYSUBMITTED</td>\n",
       "      <td>0.624</td>\n",
       "      <td>0.624</td>\n",
       "      <td>258677.423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262196</th>\n",
       "      <td>2012-02-29 23:52:01.287000+01:00</td>\n",
       "      <td>214376</td>\n",
       "      <td>W_Afhandelen leads</td>\n",
       "      <td>44.488</td>\n",
       "      <td>43.864</td>\n",
       "      <td>258721.287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262197</th>\n",
       "      <td>2012-03-01 09:26:46.736000+01:00</td>\n",
       "      <td>214376</td>\n",
       "      <td>W_Afhandelen leads</td>\n",
       "      <td>34529.937</td>\n",
       "      <td>34485.449</td>\n",
       "      <td>293206.736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262198</th>\n",
       "      <td>2012-03-01 09:27:37.118000+01:00</td>\n",
       "      <td>214376</td>\n",
       "      <td>A_DECLINED</td>\n",
       "      <td>34580.319</td>\n",
       "      <td>50.382</td>\n",
       "      <td>293257.118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262199</th>\n",
       "      <td>2012-03-01 09:27:41.325000+01:00</td>\n",
       "      <td>214376</td>\n",
       "      <td>W_Afhandelen leads</td>\n",
       "      <td>34584.526</td>\n",
       "      <td>4.207</td>\n",
       "      <td>293261.325</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>262200 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               timestamp  trace_id                activity  \\\n",
       "0       2011-10-01 00:38:44.546000+02:00    173688             A_SUBMITTED   \n",
       "1       2011-10-01 00:38:44.880000+02:00    173688       A_PARTLYSUBMITTED   \n",
       "2       2011-10-01 00:39:37.906000+02:00    173688           A_PREACCEPTED   \n",
       "3       2011-10-01 00:39:38.875000+02:00    173688  W_Completeren aanvraag   \n",
       "4       2011-10-01 11:36:46.437000+02:00    173688  W_Completeren aanvraag   \n",
       "...                                  ...       ...                     ...   \n",
       "262195  2012-02-29 23:51:17.423000+01:00    214376       A_PARTLYSUBMITTED   \n",
       "262196  2012-02-29 23:52:01.287000+01:00    214376      W_Afhandelen leads   \n",
       "262197  2012-03-01 09:26:46.736000+01:00    214376      W_Afhandelen leads   \n",
       "262198  2012-03-01 09:27:37.118000+01:00    214376              A_DECLINED   \n",
       "262199  2012-03-01 09:27:41.325000+01:00    214376      W_Afhandelen leads   \n",
       "\n",
       "               tt         te          tw  \n",
       "0           0.000      0.000  434324.546  \n",
       "1           0.334      0.334  434324.880  \n",
       "2          53.360     53.026  434377.906  \n",
       "3          54.329      0.969  434378.875  \n",
       "4       39481.891  39427.562  473806.437  \n",
       "...           ...        ...         ...  \n",
       "262195      0.624      0.624  258677.423  \n",
       "262196     44.488     43.864  258721.287  \n",
       "262197  34529.937  34485.449  293206.736  \n",
       "262198  34580.319     50.382  293257.118  \n",
       "262199  34584.526      4.207  293261.325  \n",
       "\n",
       "[262200 rows x 6 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling\n",
    "later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activity:\n",
    "one hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "oh = pd.get_dummies(df['activity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df, oh], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment\n",
    "Ther given scheme is the following:\n",
    "- recieving window of $(a_i,\\ t_{e,\\ i},\\ t_{w,\\ i},\\ t_{t,\\ i}) = e_i$. So the input to model is $\\{ e_{i},\\ e_{i-1},\\ \\dots,\\ e_{i-ws} \\}$ \n",
    "- prodice $\\hat{e}_{i+1}$\n",
    "- predict $\\hat{e}_{i+2}$ using $\\{ \\hat{e}_{i+1},\\ e_{i},\\ \\dots,\\ e_{i-ws +1} \\}$\n",
    "The metric is calculated by `environment`. It returns rewards for time prediction and for next step classifiation. So basicly `env` just stores data of trace. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Default predictor\n",
    "Need to develop(debug) `Env`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Predictor:\n",
    "    def __init__(self, default_te=60, default_act=8):\n",
    "        self.default_act = default_act\n",
    "        self.default_te = default_te\n",
    "    def predict_te(self, x):\n",
    "        in_sh = x.shape[0]\n",
    "        return torch.ones(in_sh) * self.default_te\n",
    "    \n",
    "    def predict_a(self, x):\n",
    "        in_sh = x.shape[0]\n",
    "        return torch.ones(in_sh) * self.default_act"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chose `[trace_id]` and create butch of traces, for learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_trace(trace_np_matrix, max_len):\n",
    "    need_pad = max_len - trace_np_matrix.shape[0]\n",
    "    pad = np.zeros((need_pad, trace_np_matrix.shape[1]))\n",
    "    return np.concatenate((trace_np_matrix, pad))\n",
    "\n",
    "def extract_trace_features(df, trace_id, max_len):\n",
    "    df_id = df[df['trace_id'] == t_id].drop(columns=['timestamp', 'trace_id', 'activity'])\n",
    "    trace_vals = df_id.values\n",
    "    trace_vals = fill_trace(trace_vals, max_len)\n",
    "    trace_vals = torch.as_tensor(trace_vals).unsqueeze(0)\n",
    "    return trace_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_trace_ids = list(set(df['trace_id'].values))[0: 4]\n",
    "env_matrix = None\n",
    "max_len = 0\n",
    "for t_id in env_trace_ids:\n",
    "    trace_len = df[df['trace_id'] == t_id].shape[0]\n",
    "    if max_len < trace_len:\n",
    "        max_len = trace_len\n",
    "        \n",
    "\n",
    "for _i, t_id in enumerate(env_trace_ids):\n",
    "    if env_matrix is not None:\n",
    "        \n",
    "        trace_vals = extract_trace_features(df, t_id, max_len)\n",
    "        env_matrix = torch.cat([env_matrix, trace_vals])\n",
    "    else:\n",
    "        env_matrix = extract_trace_features(df, t_id, max_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These ara 'answers', and initial input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = 2\n",
    "predictor = Predictor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = env_matrix[:, :window_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([8., 8., 8., 8.])\n",
      "tensor([60., 60., 60., 60.])\n"
     ]
    }
   ],
   "source": [
    "a = predictor.predict_a(inp)\n",
    "te = predictor.predict_te(inp)\n",
    "print(a)\n",
    "print(te)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then this predictions are inputs for next event prediction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_feature = {'te': 0, 'tt': 1, 'tw': 2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_next_input(prev_inp, next_act, next_te, column_feature):\n",
    "    out = prev_inp[:, 1:]\n",
    "    next_event = torch.zeros(prev_inp.shape[0], prev_inp.shape[2])\n",
    "    next_event[:, column_feature['te']] = next_te\n",
    "    last_event = prev_inp[:, -1].squeeze(1)\n",
    "    \n",
    "    next_event[:, column_feature['tt']] = last_event[:, column_feature['tt']] + next_te\n",
    "    \n",
    "    next_event[:, column_feature['tw']] = (last_event[:, column_feature['tw']] + next_te ) % (7 * 24 * 60 * 60)\n",
    "    # one hot transformation from https://discuss.pytorch.org/t/convert-int-into-one-hot-format/507/5\n",
    "    act_onehot = torch.FloatTensor(out.shape[0], out.shape[2] - len(column_feature))\n",
    "    act_onehot.zero_()\n",
    "    act_onehot.scatter_(1, next_act.long().view(-1, 1), 1)\n",
    "    next_event[:, len(column_feature):] = act_onehot\n",
    "\n",
    "    out = torch.cat([out, next_event.unsqueeze(1)], dim=1)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "next_inp = get_next_input(inp, a, te, column_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([342983.8270, 343043.8125], dtype=torch.float64)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_inp[0, :, 2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basicly this is for NN's predictions, but for env function which works with 1 event window is needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "next_inp_ = get_next_input(inp[0].unsqueeze(0), a[0].unsqueeze(0), te[0].unsqueeze(0), column_feature)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 27])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_inp_.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Working is snippet is just above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also `env` returns a reward for predicion. Step is applied not for tensor of events for several traces, but for 1 event of trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "te_key_times = [0., 1., 10., 60., 120., 240., 480., 1440., 2880., 4320.,\n",
    "                7200., 10080., 14400., 20160., 30240., 40320., 50400.]\n",
    "te_intervals = [(te_key_times[i], te_key_times[i+1])\n",
    "             for i in range(len(te_key_times)-1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "true: 33877.818\n",
      "pred: 60.14899826049805\n",
      "nice))))\n"
     ]
    }
   ],
   "source": [
    "# here wee neet counter to controll answers\n",
    "curr_step = 3\n",
    "trace = 2\n",
    "te_pred = next_inp[trace, -1, column_feature['tt']]\n",
    "te_true = env_matrix[trace, curr_step, column_feature['tt']]\n",
    "\n",
    "print(f'true: {te_true}\\npred: {te_pred}\\nnice))))')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_te_reward(true: torch.tensor, pred: torch.tensor, intervals):\n",
    "    for inter in intervals:\n",
    "        if (true >= inter[0]) & (true < inter[1]): # got true value in this interval\n",
    "            if (pred >= inter[0]) & (pred < inter[1]):\n",
    "                return 1\n",
    "            else:\n",
    "                return 0\n",
    "        if (pred >= inter[0]) & (pred < inter[1]): # got pred value in this interval\n",
    "            return 0\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_te_reward(true: torch.tensor, pred: torch.tensor, intervals):\n",
    "    masks = []\n",
    "    for inter in intervals:\n",
    "        true_here = (true >= inter[0]) * (true < inter[1]) \n",
    "        pred_here = (pred >= inter[0]) * (pred < inter[1])\n",
    "        masks.append(true_here * pred_here)\n",
    "    out = torch.stack(masks).T.sum(dim=1)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 1])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true = torch.tensor([62., 700., 61.])\n",
    "pred = torch.tensor([700., 62., 62.]) \n",
    "get_te_reward(true=true, pred=pred, intervals=te_intervals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "true = torch.tensor([62., 700., 61.])\n",
    "pred = torch.tensor([700., 62., 62.]) \n",
    "assert (get_te_reward(true=true, pred=pred, intervals=te_intervals) == torch.tensor([0, 0, 1]).bool()).all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pipe line to deal with multiple traces needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_act_reward(true_act_oh, pred_act_oh):\n",
    "    mult = (true_act_oh * pred_act_oh)\n",
    "    return mult.sum(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert get_act_reward(true_act_oh=torch.tensor([[1, 0, 0, 0]]), pred_act_oh=torch.tensor([[1, 0, 0, 0]])) == 1\n",
    "assert get_act_reward(true_act_oh=torch.tensor([[0, 1, 0, 0]]), pred_act_oh=torch.tensor([[1, 0, 0, 0]])) == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 0])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " get_act_reward(true_act_oh=torch.tensor([[1, 0, 0, 0],\n",
    "                                          [1, 0, 0, 0]\n",
    "                                         ]),\n",
    "                pred_act_oh=torch.tensor([[1, 0, 0, 0],\n",
    "                                          [0, 1, 0, 0]\n",
    "                                         ]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can prodice all the env must do in working cycle:\n",
    "```\n",
    "next_s, (reward_te, reward_act), is_done, add_inf = env.step(next_te, next_act)\n",
    "```\n",
    "Let's build class! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PMEnv(gym.Env):\n",
    "    def __init__(self, data: torch.tensor, intervals_te_rew, column_to_time_features, window_size):\n",
    "        self.data = data\n",
    "        self.pred_counter = 1 + window_size\n",
    "        self.trace_index = None\n",
    "        self.intervals = intervals_te_rew\n",
    "        self.column_feature = column_to_time_features\n",
    "        self.win = window_size\n",
    "        self.given_state = None\n",
    "        \n",
    "    def reset(self, trace_n=None):\n",
    "        self.pred_counter = 1 + self.win\n",
    "        out = self.data[:, :window_size]\n",
    "        self.given_state = out\n",
    "        self.trace_index = trace_n\n",
    "        return out\n",
    "        \n",
    "    def step(self, next_te: torch.tensor, next_act: torch.tensor):\n",
    "        '''\n",
    "        returns: next_s, (reward_te, reward_act), is_done, add_inf\n",
    "        '''\n",
    "        te_rew = get_te_reward(true=self.data[:, self.pred_counter, self.column_feature['te']],\n",
    "                               pred=next_te, intervals=self.intervals)\n",
    "        \n",
    "        true_act_oh = self.data[:, self.pred_counter, len(column_feature):]\n",
    "\n",
    "        # TODO here rises an error\n",
    "        pred_act_oh = torch.zeros(self.data.shape[0], self.data.shape[-1] - len(self.column_feature), dtype=int)\n",
    "        pred_act_oh[range(pred_act_oh.shape[0]), next_act.long()] = 1\n",
    "        \n",
    "        act_rew = get_act_reward(true_act_oh=true_act_oh, pred_act_oh=pred_act_oh)\n",
    "        \n",
    "        next_s = get_next_input(prev_inp=self.given_state,\n",
    "                                next_act=next_act,\n",
    "                                next_te=next_te,\n",
    "                                column_feature=self.column_feature)\n",
    "        self.given_state = next_s\n",
    "        \n",
    "        is_done = (self.pred_counter == (self.data.shape[1] - 1))\n",
    "        \n",
    "        self.pred_counter += 1\n",
    "        return next_s, (te_rew, act_rew), is_done, {}\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gonna run this and go chill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 52, 27])\n"
     ]
    }
   ],
   "source": [
    "print(env_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = PMEnv(data=env_matrix, intervals_te_rew=te_intervals, column_to_time_features=column_feature, window_size=window_size)\n",
    "\n",
    "inp = env.reset()\n",
    "# predictor is a NN, it works with batches of states\n",
    "is_done = False\n",
    "while not is_done:\n",
    "    n_traces = inp.shape[0]\n",
    "    next_act = predictor.predict_a(inp.view(n_traces, -1))\n",
    "    next_te = predictor.predict_te(inp.view(n_traces, -1))\n",
    "    inp, (reward_te, reward_act), is_done, add_inf = env.step(next_te, next_act)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM-based NN\n",
    "Ok here I gonna quiqly build some simply NN, which behaves just like predictor(which was used for debug).\n",
    "Later this NN will be used for Q-Learning\n",
    "``` python\n",
    "env_matrix = [n_traces=4, max_seq_len=52, features=27]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, output_layer, input_size=27 * 2, hidden_layer=64, n_lstm=1):\n",
    "        super(Net, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_size=input_size, hidden_size=hidden_layer, batch_first=True, num_layers=n_lstm)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc = nn.Linear(hidden_layer, output_layer)\n",
    "    \n",
    "    def forward(self, x, h):\n",
    "        x, (h, c) = self.lstm(x, (h[0], h[1]))\n",
    "        x = self.relu(x)\n",
    "        x = self.fc(x)\n",
    "        x = self.relu(x)\n",
    "        return x, (h, c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "input = (n_traces, max_len, features) # nn.LSTM(..., batch_first=True)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "output = out, (h, c)\n",
    "out.shape = (n_traces, max_len, features) # nn.LSTM(..., batch_first=True)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loop with env, LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = PMEnv(data=env_matrix, intervals_te_rew=te_intervals, column_to_time_features=column_feature, window_size=window_size)\n",
    "\n",
    "lstm_model_te = Net(output_layer=1).float()\n",
    "lstm_model_act = Net(output_layer=n_classes).float()\n",
    "\n",
    "inp = env.reset()\n",
    "n_traces = inp.shape[0]\n",
    "# predictor is a NN, it works with batches of states\n",
    "is_done = False\n",
    "h_a = torch.zeros(1, n_traces, 64)\n",
    "c_a = torch.zeros(1, n_traces, 64)\n",
    "h_te = torch.zeros(1, n_traces, 64)\n",
    "c_te = torch.zeros(1, n_traces, 64)\n",
    "while not is_done:\n",
    "    inp = inp.view(n_traces, 1, -1).float()\n",
    "    next_act, (h_a, c_a) = lstm_model_act(inp, (h_a, c_a))\n",
    "    next_te, (h_te, c_te) = lstm_model_te(inp, (h_te, c_te))\n",
    "    \n",
    "    next_act = next_act.view(n_traces, -1)\n",
    "    next_act = next_act.argmax(dim=1).view(n_traces, -1)\n",
    "    \n",
    "    next_te = next_te.view(n_traces)\n",
    "        \n",
    "    inp, (reward_te, reward_act), is_done, add_inf = env.step(next_te, next_act)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agent\n",
    "### Nets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NetTe(nn.Module):\n",
    "    def __init__(self, input_size, hidden_layer, n_lstm, te_intervals):\n",
    "        super(NetTe, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_size=input_size, hidden_size=hidden_layer, batch_first=True, num_layers=n_lstm)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc = nn.Linear(hidden_layer, len(te_intervals))\n",
    "    \n",
    "    def forward(self, x, h):\n",
    "        x, (h, c) = self.lstm(x, (h[0], h[1]))\n",
    "        x = self.relu(x)\n",
    "        x = self.fc(x)\n",
    "        return x, (h, c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NetAct(nn.Module):\n",
    "    def __init__(self, input_size, hidden_layer, n_lstm, out_shape):\n",
    "        super(NetAct, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_size=input_size, hidden_size=hidden_layer, batch_first=True, num_layers=n_lstm)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc = nn.Linear(hidden_layer, out_shape)\n",
    "    \n",
    "    def forward(self, x, h):\n",
    "        x, (h, c) = self.lstm(x, (h[0], h[1]))\n",
    "        x = self.relu(x)\n",
    "        x = self.fc(x)\n",
    "        return x, (h, c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgentTeDiscrete:\n",
    "    def __init__(self, input_size, hidden_layer, n_lstm, te_intervals):\n",
    "        self.net = NetTe(input_size, hidden_layer, n_lstm, te_intervals)\n",
    "        self.target_net = NetTe(input_size, hidden_layer, n_lstm, te_intervals)\n",
    "        self.te_intervals = te_intervals\n",
    "        \n",
    "    def sample_action(self, x, hidden, stoch=False):\n",
    "        q_values, hidden = self.net(x, hidden)\n",
    "        q_values = q_values.view(q_values.shape[0], q_values.shape[2])\n",
    "        \n",
    "        if stoch == False:\n",
    "            t_idx = q_values.argmax(dim=1)\n",
    "            out = torch.zeros(t_idx.shape)\n",
    "            for i in range(out.shape[0]):\n",
    "                out[i] = (self.te_intervals[t_idx[i]][0] + self.te_intervals[t_idx[i]][1]) / 2.\n",
    "                \n",
    "        return out, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgentAct:\n",
    "    def __init__(self, input_size, hidden_layer, n_lstm, out_shape):\n",
    "        self.net = NetAct(input_size, hidden_layer, n_lstm, out_shape)\n",
    "        self.target_net = NetAct(input_size, hidden_layer, n_lstm, out_shape)\n",
    "        \n",
    "        self.te_intervals = te_intervals\n",
    "        \n",
    "    def sample_action(self, x, hidden, stoch=False):\n",
    "        q_values, hidden = self.net(x, hidden)\n",
    "        q_values = q_values.view(q_values.shape[0], q_values.shape[2])\n",
    "        \n",
    "        if stoch == False:\n",
    "            act_idx = q_values.argmax(dim=1)\n",
    "            \n",
    "        return act_idx, hidden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replay Buffer\n",
    "shamelessly stolen from [here](https://pytorch.org/tutorials/intermediate/reinforcement_q_learning.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "class ReplayMemory(object):\n",
    "\n",
    "    def __init__(self, capacity):\n",
    "        self.capacity = capacity\n",
    "        self.memory = []\n",
    "        self.position = 0\n",
    "\n",
    "    def push(self, datum):\n",
    "        \"\"\"Saves a transition.\"\"\"\n",
    "        if len(self.memory) < self.capacity:\n",
    "            self.memory.append(None)\n",
    "        self.memory[self.position] = datum\n",
    "        self.position = (self.position + 1) % self.capacity\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        return random.sample(self.memory, batch_size)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "replay_buffer = ReplayMemory(2 ** 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = PMEnv(data=env_matrix, intervals_te_rew=te_intervals, column_to_time_features=column_feature, window_size=window_size)\n",
    "\n",
    "te_agent = AgentTeDiscrete(input_size=27 * 2, hidden_layer=64, n_lstm=1, te_intervals=te_intervals)\n",
    "ac_agent = AgentAct(input_size=27 * 2, hidden_layer=64, n_lstm=1, out_shape=n_classes)\n",
    "\n",
    "lstm_model_act = Net(output_layer=n_classes).float()\n",
    "\n",
    "inp = env.reset()\n",
    "n_traces = inp.shape[0]\n",
    "inp = inp.view(n_traces, 1, -1).float()\n",
    "# predictor is a NN, it works with batches of states\n",
    "is_done = False\n",
    "h_a = torch.zeros(1, n_traces, 64)\n",
    "c_a = torch.zeros(1, n_traces, 64)\n",
    "h_t = torch.zeros(1, n_traces, 64)\n",
    "c_t = torch.zeros(1, n_traces, 64)\n",
    "while not is_done:\n",
    "       \n",
    "    next_ac, (h_a, c_a) = ac_agent.sample_action(x=inp, hidden=(h_a, c_a))\n",
    "    next_te, (h_t, c_t) = te_agent.sample_action(x=inp, hidden=(h_t, c_t))\n",
    "        \n",
    "    n_inp, (reward_te, reward_act), is_done, add_inf = env.step(next_te, next_ac)\n",
    "    n_inp = n_inp.view(n_traces, 1, -1).float()\n",
    "    datum = (inp, (next_te, next_ac), n_inp, (reward_te, reward_act))\n",
    "    replay_buffer.push(datum)\n",
    "    \n",
    "    inp = n_inp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[9.6000e+02, 2.9472e+05, 3.2904e+04, 0.0000e+00, 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00, 9.6000e+02, 2.9568e+05, 3.3864e+04,\n",
       "           0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "           1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00]],\n",
       " \n",
       "         [[9.6000e+02, 2.9472e+05, 3.3247e+04, 0.0000e+00, 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00, 9.6000e+02, 2.9568e+05, 3.4207e+04,\n",
       "           0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "           1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00]],\n",
       " \n",
       "         [[9.6000e+02, 2.9472e+05, 3.3538e+04, 0.0000e+00, 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00, 9.6000e+02, 2.9568e+05, 3.4498e+04,\n",
       "           0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "           1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00]],\n",
       " \n",
       "         [[9.6000e+02, 2.9472e+05, 3.3799e+04, 0.0000e+00, 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00, 9.6000e+02, 2.9568e+05, 3.4759e+04,\n",
       "           0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "           1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00]]]),\n",
       " (tensor([960., 960., 960., 960.]), tensor([20, 20, 20, 20])),\n",
       " tensor([[[9.6000e+02, 2.9568e+05, 3.3864e+04, 0.0000e+00, 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00, 9.6000e+02, 2.9664e+05, 3.4824e+04,\n",
       "           0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "           1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00]],\n",
       " \n",
       "         [[9.6000e+02, 2.9568e+05, 3.4207e+04, 0.0000e+00, 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00, 9.6000e+02, 2.9664e+05, 3.5167e+04,\n",
       "           0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "           1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00]],\n",
       " \n",
       "         [[9.6000e+02, 2.9568e+05, 3.4498e+04, 0.0000e+00, 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00, 9.6000e+02, 2.9664e+05, 3.5458e+04,\n",
       "           0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "           1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00]],\n",
       " \n",
       "         [[9.6000e+02, 2.9568e+05, 3.4759e+04, 0.0000e+00, 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00, 9.6000e+02, 2.9664e+05, 3.5719e+04,\n",
       "           0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "           1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00]]]),\n",
       " (tensor([0, 0, 0, 0]), tensor([0., 0., 0., 0.], dtype=torch.float64)))"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "replay_buffer.sample(2)[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
